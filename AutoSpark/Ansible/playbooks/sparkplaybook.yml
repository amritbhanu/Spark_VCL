---
- hosts: sparknodes
  vars:
    master: "{{ MASTER_YES }}"
    spark_url: "{{ SPARK_URL }}"
    user: "{{ USER }}"
    master_ip: "{{ MASTER_IP }}"
  user: "{{user}}"

  tasks:
   - name: Adding Java 8 key
     shell: sudo su - root -c 'sudo add-apt-repository ppa:openjdk-r/ppa -y'
     args:
        executable: /bin/bash

   - name: Install list of packages
     sudo: true
     apt: name={{item}} state=installed update_cache=true
     with_items:
      - libblas-dev
      - liblapack-dev
      - openjdk-8-jdk
      - libatlas-base-dev
      - gfortran
      - python-matplotlib
      - ipython
      - ipython-notebook

   - name: create pip dir
     sudo: false
     file: path=/home/{{user}}/pip state=directory mode=0755

   - name: download pip Upgrade
     sudo: false
     get_url: url=https://pypi.python.org/packages/e7/a8/7556133689add8d1a54c0b14aeff0acb03c64707ce100ecd53934da1aa13/pip-8.1.2.tar.gz dest=/home/{{user}}/pip/

   - name: Unarchive pip download
     sudo: false
     unarchive: src=/home/{{user}}/pip/pip-8.1.2.tar.gz dest=/home/{{user}}/pip copy=no

   - name: Run python command
     sudo: true
     command: chdir=/home/{{user}}/pip/pip-8.1.2/ python setup.py install
 
   - name: Upgrade python pip
     shell: sudo su - root -c 'sudo pip install --upgrade pip'
     args:
        executable: /bin/bash
     
   - name: install scipy numpy scikit-learn pandas jupyter
     sudo: true
     command: pip install -U scipy numpy scikit-learn pandas jupyter

   - name: create spark dir
     sudo: false
     file: path=/home/{{user}}/spark state=directory mode=0755

   - name: download spark
     sudo: false
     get_url: url=http://ftp.wayne.edu/apache//spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz dest=/home/{{user}}/spark/

   - name: Unarchive Spark download
     sudo: false
     unarchive: src=/home/{{user}}/spark/spark-2.2.1-bin-hadoop2.7.tgz dest=/home/{{user}}/spark copy=no

   - name: Delete spark_folder
     sudo: true
     shell: sudo su - root -c 'rm -rf /home/{{user}}/spark/spark_latest'
     args:
        executable: /bin/bash

   - name: Delete hadoop_folder
     sudo: true
     shell: sudo su - root -c 'rm -rf /home/{{user}}/hadoop'

   - name: Move spark dir to spark_latest
     sudo: false
     command: mv /home/{{user}}/spark/spark-2.2.1-bin-hadoop2.7 /home/{{user}}/spark/spark_latest

   - name: Changing ownership of spark directory
     sudo: true
     command: chown -R {{user}} /home/{{user}}/spark/spark_latest

   - name: download hadoop
     sudo: false
     get_url: url=http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz dest=/home/{{user}}/

   - name: Unarchive hadoop download
     sudo: false
     unarchive: src=/home/{{user}}/hadoop-2.9.0.tar.gz dest=/home/{{user}}/ copy=no

   - name: Move hadoop-2 dir to hadoop
     sudo: false
     command: mv /home/{{user}}/hadoop-2.9.0 /home/{{user}}/hadoop

   - name: Create app/tmp
     sudo: true
     command: mkdir -p /app/hadoop/tmp

   - name: Changing ownership of app/data
     sudo: true
     command: chown -R {{user}} /app/hadoop/tmp

   - name: writing to bashrc
     lineinfile: dest=/home/{{user}}/.bashrc
                insertafter=EOF
                line='\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport HADOOP_INSTALL=/home/{{user}}/hadoop\nexport PATH=$PATH:$HADOOP_INSTALL/bin\nexport PATH=$PATH:$HADOOP_INSTALL/sbin\nexport HADOOP_MAPRED_HOME=$HADOOP_INSTALL\nexport HADOOP_COMMON_HOME=$HADOOP_INSTALL\nexport HADOOP_HDFS_HOME=$HADOOP_INSTALL\nexport YARN_HOME=$HADOOP_INSTALL\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native\nexport HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib/native"'

   - name: update bashrc
     sudo: false
     shell: source /home/{{user}}/.bashrc
     args:
        executable: /bin/bash

   - name: Create directroy namenode
     sudo: false
     command: mkdir -pv /home/{{user}}/hadoop/data/namenode

   - name: Create directroy logs
     sudo: false
     command: mkdir -pv /home/{{user}}/hadoop/logs

   - name: Create directroy datanode
     sudo: false
     command: mkdir -pv /home/{{user}}/hadoop/data/datanode

   - name: Changing permissions of app data
     sudo: true
     command: chmod 750 /app/hadoop/tmp

   - name: writing to hadoop-env.sh
     lineinfile: dest=/home/{{user}}/hadoop/etc/hadoop/hadoop-env.sh
                regexp=''
                insertafter=EOF
                line='export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport HADOOP_OPTS=-Djava.net.preferIPv4Stack=true'

   - name: Delete yarn file
     sudo: true
     shell: truncate /home/{{user}}/hadoop/etc/hadoop/yarn-site.xml --size 0
     args:
        executable: /bin/bash

   - name: Delete hdfs file
     sudo: true
     shell: truncate /home/{{user}}/hadoop/etc/hadoop/hdfs-site.xml --size 0
     args:
        executable: /bin/bash

   - name: Delete core file
     sudo: true
     shell: truncate /home/{{user}}/hadoop/etc/hadoop/core-site.xml --size 0
     args:
        executable: /bin/bash

   - name: add lines in hdfs-site.xml
     lineinfile: dest=/home/{{user}}/hadoop/etc/hadoop/hdfs-site.xml
                regexp=''
                insertafter='EOF'
                line='<?xml version="1.0" encoding="UTF-8"?>\n<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n<configuration>\n\t<property>\n\t\t<name>dfs.datanode.data.dir</name>\n\t\t<value>file:///home/{{user}}/hadoop/data/datanode</value>\n\t\t<description>DataNode directory</description>\n\t</property>\n\t<property>\n\t\t<name>dfs.replication</name>\n\t\t<value>3</value>\n\t</property>\n\t<property>\n\t\t<name>dfs.permissions</name>\n\t\t<value>false</value>\n\t</property>\n\t<property>\n\t\t<name>dfs.datanode.use.datanode.hostname</name>\n\t\t<value>false</value>\n\t</property>\n\t<property>\n\t\t<name>dfs.namenode.http-address</name>\n\t\t<value>{{master_ip}}:50070</value>\n\t\t<description>Your NameNode hostname for http access.</description>\n\t</property>\n\t<property>\n\t\t<name>dfs.namenode.secondary.http-address</name>\n\t\t<value>{{master_ip}}:50090</value>\n\t\t<description>Your Secondary NameNode hostname for http access.</description>\n\t</property>\n</configuration>'
                state=present

   - name: add lines in core-site.xml
     lineinfile: dest=/home/{{user}}/hadoop/etc/hadoop/core-site.xml
                regexp=''
                insertafter='EOF'
                line='<?xml version="1.0" encoding="UTF-8"?>\n<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n<configuration>\n\t<property>\n\t\t<name>hadoop.tmp.dir</name>\n\t\t<value>/app/hadoop/tmp</value>\n\t</property>\n\t<property>\n\t\t<name>fs.defaultFS</name>\n\t\t<value>hdfs://{{master_ip}}/</value>\n\t\t<description>NameNode URI</description>\n\t</property>\n</configuration>'
                state=present

   - name: Move mapred template to mapred-site
     sudo: false
     command: cp /home/{{user}}/hadoop/etc/hadoop/mapred-site.xml.template /home/{{user}}/hadoop/etc/hadoop/mapred-site.xml

   - name: add lines in mapred-site.xml
     lineinfile: dest=/home/{{user}}/hadoop/etc/hadoop/mapred-site.xml
                regexp='^<configuration>'
                insertafter='<configuration>'
                line='<configuration>\n\t<property>\n\t\t<name>mapreduce.framework.name</name>\n\t\t<value>yarn</value>\n\t</property>'
                state=present

   - name: add lines in yarn-site.xml
     lineinfile: dest=/home/{{user}}/hadoop/etc/hadoop/yarn-site.xml
                regexp=''
                insertafter='EOF'
                line='<?xml version="1.0"?>\n<configuration>\n\t<property>\n\t\t<name>yarn.nodemanager.aux-services</name>\n\t\t<value>mapreduce_shuffle</value>\n\t</property>\n\t<property>\n\t\t<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>\n\t\t<value>org.apache.hadoop.mapred.ShuffleHandler</value>\n\t</property>\n\t<property>\n\t\t<name>yarn.resourcemanager.resource-tracker.address</name>\n\t\t<value>{{master_ip}}:8025</value>\n\t</property>\n\t<property>\n\t<name>yarn.resourcemanager.scheduler.address</name>\n\t\t<value>{{master_ip}}:8030</value>\n\t</property>\n\t<property>\n\t\t<name>yarn.resourcemanager.address</name>\n\t\t<value>{{master_ip}}:8050</value>\n\t</property>\n</configuration>'
                state=present

   - name: Move spark-env.template dir to spark-env.sh
     sudo: false
     command: mv /home/{{user}}/spark/spark_latest/conf/spark-env.sh.template /home/{{user}}/spark/spark_latest/conf/spark-env.sh

   - name: writing to spark-env.sh
     lineinfile: dest=/home/{{user}}/spark/spark_latest/conf/spark-env.sh
                regexp=''
                insertafter=EOF
                line='export SPARK_MASTER_MEMORY="6G"\nexport SPARK_DRIVER_MEMORY="6G"\nexport SPARK_WORKER_MEMORY="6G"\nexport SPARK_EXECUTOR_MEMORY="6G"'


   - name: Changing permissions of hadoop
     sudo: true
     command: chmod -R 777 /home/{{user}}/hadoop

   - name: Changing ownership
     sudo: true
     command: chown -R {{user}} /home/{{user}}/hadoop
